[
    {
        "label": "src.peak_area",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "src.peak_area",
        "description": "src.peak_area",
        "detail": "src.peak_area",
        "documentation": {}
    },
    {
        "label": "src.store_results",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "detail": "src.store_results",
        "documentation": {}
    },
    {
        "label": "pathlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pathlib",
        "description": "pathlib",
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "quad",
        "importPath": "scipy.integrate",
        "description": "scipy.integrate",
        "isExtraImport": true,
        "detail": "scipy.integrate",
        "documentation": {}
    },
    {
        "label": "quad",
        "importPath": "scipy.integrate",
        "description": "scipy.integrate",
        "isExtraImport": true,
        "detail": "scipy.integrate",
        "documentation": {}
    },
    {
        "label": "interp1d",
        "importPath": "scipy.interpolate",
        "description": "scipy.interpolate",
        "isExtraImport": true,
        "detail": "scipy.interpolate",
        "documentation": {}
    },
    {
        "label": "interp1d",
        "importPath": "scipy.interpolate",
        "description": "scipy.interpolate",
        "isExtraImport": true,
        "detail": "scipy.interpolate",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "reduce",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "reduce",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "Observer",
        "importPath": "watchdog.observers",
        "description": "watchdog.observers",
        "isExtraImport": true,
        "detail": "watchdog.observers",
        "documentation": {}
    },
    {
        "label": "FileSystemEventHandler",
        "importPath": "watchdog.events",
        "description": "watchdog.events",
        "isExtraImport": true,
        "detail": "watchdog.events",
        "documentation": {}
    },
    {
        "label": "src.preprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "src.preprocess",
        "description": "src.preprocess",
        "detail": "src.preprocess",
        "documentation": {}
    },
    {
        "label": "src.analysis",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "src.analysis",
        "description": "src.analysis",
        "detail": "src.analysis",
        "documentation": {}
    },
    {
        "label": "result",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "cm",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "parser",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "Bag_analysis",
        "kind": 6,
        "importPath": "src.analysis",
        "description": "src.analysis",
        "peekOfCode": "class Bag_analysis:\n    def __init__(\n        self,\n        sty_const: float,\n        c0_tmsp: float,\n        bagresult: store_results.Bag_result,\n        tmsp: peak_area.Chemical_shift,\n        chemicals: list[peak_area.Chemical_shift],\n        nameoption=\"\",\n    ) -> None:",
        "detail": "src.analysis",
        "documentation": {}
    },
    {
        "label": "analysis_internal_standard_tmsp",
        "kind": 2,
        "importPath": "src.analysis",
        "description": "src.analysis",
        "peekOfCode": "def analysis_internal_standard_tmsp(\n    sty_const: float,\n    c0_tmsp: float,\n    bagresult: store_results.Bag_result,\n    tmsp: peak_area.Chemical_shift,\n    *args: list[peak_area.Chemical_shift],\n):\n    \"\"\"\n    Analysis with internal standard TMSP-d4: Compare chemical shift to internal standard\n    \"\"\"",
        "detail": "src.analysis",
        "documentation": {}
    },
    {
        "label": "save_data_in_baganalyis",
        "kind": 2,
        "importPath": "src.analysis",
        "description": "src.analysis",
        "peekOfCode": "def save_data_in_baganalyis(data, baganalysis: Bag_analysis, nameoption=str):\n    if isinstance(data, dict):\n        dict_path = os.path.join(baganalysis.analysis_dir, nameoption + \".npy\")\n        np.save(dict_path, data)\n        # print(f\"save {nameoption +'.npy'} in {dict_path}\")\n        # setattr(bagresult, nameoption, dict_path)\n        return dict_path\n    if isinstance(data, pd.DataFrame):\n        df_path = os.path.join(baganalysis.analysis_dir, nameoption + \".csv\")\n        data.to_csv(df_path, index=False)",
        "detail": "src.analysis",
        "documentation": {}
    },
    {
        "label": "load_baganalysis",
        "kind": 2,
        "importPath": "src.analysis",
        "description": "src.analysis",
        "peekOfCode": "def load_baganalysis(baganalysis_path: os.path):\n    file = pathlib.Path(baganalysis_path)\n    if file.exists() == False:\n        print(f\"there is no bagdata object\")\n    else:\n        return pickle.load(open(baganalysis_path, \"rb\"))",
        "detail": "src.analysis",
        "documentation": {}
    },
    {
        "label": "Live_analysis",
        "kind": 6,
        "importPath": "src.live_dev",
        "description": "src.live_dev",
        "peekOfCode": "class Live_analysis:\n    def __init__(self, baganalysis: analysis.Bag_analysis):\n        self.baganalysis = baganalysis\n        self.w = Watcher(self.baganalysis)\n    def live_update(self):\n        self.w.run()\nclass Watcher:\n    warnings.filterwarnings(\"ignore\")\n    def __init__(self, baganalysis: analysis.Bag_analysis):\n        self.observer = Observer()",
        "detail": "src.live_dev",
        "documentation": {}
    },
    {
        "label": "Watcher",
        "kind": 6,
        "importPath": "src.live_dev",
        "description": "src.live_dev",
        "peekOfCode": "class Watcher:\n    warnings.filterwarnings(\"ignore\")\n    def __init__(self, baganalysis: analysis.Bag_analysis):\n        self.observer = Observer()\n        self.baganalysis = baganalysis\n        self.DIRECTORY_TO_WATCH = baganalysis.bagresult.bagdata.source_folder\n    def run(self):\n        event_handler = Handler(self.baganalysis)\n        self.observer.schedule(event_handler, self.DIRECTORY_TO_WATCH, recursive=True)\n        self.observer.start()",
        "detail": "src.live_dev",
        "documentation": {}
    },
    {
        "label": "Handler",
        "kind": 6,
        "importPath": "src.live_dev",
        "description": "src.live_dev",
        "peekOfCode": "class Handler(FileSystemEventHandler):\n    def __init__(self, baganalysis: analysis.Bag_analysis):\n        super().__init__()\n        self.baganalysis = baganalysis\n        self.csv_dict = {}\n    warnings.filterwarnings(\"ignore\")\n    def on_created(self, event):\n        file = str(event.src_path)\n        if file.endswith(\"processed.csv\"):\n            warnings.filterwarnings(\"ignore\")",
        "detail": "src.live_dev",
        "documentation": {}
    },
    {
        "label": "update_newanalysis",
        "kind": 2,
        "importPath": "src.live_dev",
        "description": "src.live_dev",
        "peekOfCode": "def update_newanalysis(f_0, t_0, baganalysis: analysis.Bag_analysis):\n    chemicals, sty_const, c0_tmsp, tmsp = (\n        baganalysis.chemicals,\n        baganalysis.sty_const,\n        baganalysis.c0_tmsp,\n        baganalysis.tmsp,\n    )\n    if tmsp not in set(chemicals):\n        chemicals.append(tmsp)\n    df_list = []",
        "detail": "src.live_dev",
        "documentation": {}
    },
    {
        "label": "update_baganalysis",
        "kind": 2,
        "importPath": "src.live_dev",
        "description": "src.live_dev",
        "peekOfCode": "def update_baganalysis(baganalysis: analysis.Bag_analysis):\n    old_infor = pd.read_csv(baganalysis.bagresult.bagdata.information)\n    print(f'copy{old_infor[\"TimeGap\"].values[-1]} now in Targetfolder')\n    _target_folder = baganalysis.bagresult.bagdata.target_folder\n    shutil.copy(\n        old_infor[\"Source_Path\"].values[-1],\n        os.path.join(_target_folder, str(old_infor[\"TimeGap\"].values[-1]) + \".csv\"),\n    )\n    # update bagresult.datadict\n    new_df = pd.read_csv(old_infor[\"Source_Path\"].values[-1])",
        "detail": "src.live_dev",
        "documentation": {}
    },
    {
        "label": "update_bagdata",
        "kind": 2,
        "importPath": "src.live_dev",
        "description": "src.live_dev",
        "peekOfCode": "def update_bagdata(bagdata: preprocess.Bag_data, event):\n    root = os.path.split(event.src_path)[0]\n    start_time = preprocess.get_name_start_time(root)\n    old_infor = pd.read_csv(bagdata.information)\n    if len(old_infor) == 0:\n        new_timegap = 0\n    else:\n        tem_timegap = (\n            start_time - pd.to_datetime(np.min(old_infor[\"DateTime\"]))\n        ).total_seconds()",
        "detail": "src.live_dev",
        "documentation": {}
    },
    {
        "label": "Chemical_shift",
        "kind": 6,
        "importPath": "src.peak_area",
        "description": "src.peak_area",
        "peekOfCode": "class Chemical_shift:\n    def __init__(self, name: str, nr_proton: float, ppmstr: float, ppmend: float):\n        self.name = name\n        self.ppmstr = ppmstr\n        self.ppmend = ppmend\n        self.nr_proton = nr_proton\n        self.shilf_intervall = [ppmstr, ppmend]\n    def peak_area(self, bagresult: store_results.Bag_result):\n        peak_area_df = compute_single_peak_area(bagresult, self)\n        return peak_area_df",
        "detail": "src.peak_area",
        "documentation": {}
    },
    {
        "label": "compute_single_peak_area",
        "kind": 2,
        "importPath": "src.peak_area",
        "description": "src.peak_area",
        "peekOfCode": "def compute_single_peak_area(\n    bag_result: store_results.Bag_result, chemical_shift: Chemical_shift\n) -> pd.DataFrame:\n    \"\"\"\n    Develop fucntions for compute peaks size\n    - take the interpolation_dict and frequency intervall as inputs.\n    - Return df with col: frequency_intervall and row_index: time\n    \"\"\"\n    interpolate_dict = bag_result.interpolatefunct_dict\n    peak_area_dict = {}",
        "detail": "src.peak_area",
        "documentation": {}
    },
    {
        "label": "compute_multiple_peak_area",
        "kind": 2,
        "importPath": "src.peak_area",
        "description": "src.peak_area",
        "peekOfCode": "def compute_multiple_peak_area(\n    bag_result: store_results.Bag_result, *args: list[Chemical_shift]\n) -> pd.DataFrame:\n    df_list = [\n        compute_single_peak_area(bag_result, chemical) for chemical in list(args)\n    ]\n    peakarea_df = reduce(lambda df1, df2: pd.merge(df1, df2, on=\"Time\"), df_list)\n    return peakarea_df",
        "detail": "src.peak_area",
        "documentation": {}
    },
    {
        "label": "plot_3D",
        "kind": 2,
        "importPath": "src.plot",
        "description": "src.plot",
        "peekOfCode": "def plot_3D(\n    bag_result: store_results.Bag_result,\n    timestr=0,\n    timeend=100 ** 100,\n    ppmstr=-27,\n    ppmend=37,\n    view_op1=10,\n    view_op2=30,\n):\n    data_df = bag_result.make_plot_data()",
        "detail": "src.plot",
        "documentation": {}
    },
    {
        "label": "plot_2d",
        "kind": 2,
        "importPath": "src.plot",
        "description": "src.plot",
        "peekOfCode": "def plot_2d(\n    bag_result: store_results.Bag_result,\n    timestr=0,\n    timeend=100 ** 100,\n    ppmstr=-27,\n    ppmend=37,\n    plot_option=\"ppm\",\n):\n    \"\"\"\n    make 2D plot",
        "detail": "src.plot",
        "documentation": {}
    },
    {
        "label": "Bag_data",
        "kind": 6,
        "importPath": "src.preprocess",
        "description": "src.preprocess",
        "peekOfCode": "class Bag_data:\n    \"\"\"\n    Create a new data_batch object in destination_folder from the given source_folder and start_date_time.\n    All the csv files in which are created after start_date_time in source_folder to target_folder and rename it as Time_Gap.\n    The information of all the csv files will be saved as information.csv  in destination_folder.\n        destination_folder: where you want to store the data of the current experiment.\n        source_folder: where the NMR machine exports the data.\n        start_date_time: the desired start time for input the files from source_folder.\n        target_folder: where all the csv files are.\n        information: The information of all the csv files.",
        "detail": "src.preprocess",
        "documentation": {}
    },
    {
        "label": "makefile_with_time",
        "kind": 2,
        "importPath": "src.preprocess",
        "description": "src.preprocess",
        "peekOfCode": "def makefile_with_time(\n    source_folder: str, target_folder: str, start_date_time: datetime\n):\n    \"\"\"\n    The  makefile_with_time(source_folder,target_folder, start_date_time) will\n    copy all the csv files which are created after start_date_time in source_folder\n    to target_folder and rename it as Time_Gap. The information of all the csv\n    files will be saved as information.csv in parent_dir of target_foler.\n    ----------\n    source_folder: str",
        "detail": "src.preprocess",
        "documentation": {}
    },
    {
        "label": "get_csv_file_with_time",
        "kind": 2,
        "importPath": "src.preprocess",
        "description": "src.preprocess",
        "peekOfCode": "def get_csv_file_with_time(source_folder: str, start_date_time: datetime):\n    \"\"\"The get_csv_file_with_time get the information of all the csv files,\n    which are created after start_date_time in source folder.\n    This returns a padas dataframe with column 'start_time', 'path', 'time_gap'.\n    \"\"\"\n    li_file_path = []\n    li_file_name = []\n    for root, dirs, files in os.walk(source_folder):\n        for tem_file in files:\n            file = str(tem_file)",
        "detail": "src.preprocess",
        "documentation": {}
    },
    {
        "label": "get_name_start_time",
        "kind": 2,
        "importPath": "src.preprocess",
        "description": "src.preprocess",
        "peekOfCode": "def get_name_start_time(csv_path: str):\n    \"\"\"The get_name_start_time will go to the path,\n    where the exported csv is and read the acqu.par as text files.\n    The value of start_time will be taken as output.\n    \"\"\"\n    os.chdir(csv_path)\n    df = pd.read_csv(\"acqu.par\", delimiter=\"=\")\n    name = df[df.columns[1]][2]\n    return parser.parse(name.replace(\" \", \"\")[1:-1])\ndef list_all_folder(folder: str):",
        "detail": "src.preprocess",
        "documentation": {}
    },
    {
        "label": "list_all_folder",
        "kind": 2,
        "importPath": "src.preprocess",
        "description": "src.preprocess",
        "peekOfCode": "def list_all_folder(folder: str):\n    tem_ls_dir = list(os.listdir(folder))\n    print(tem_ls_dir)\n    return tem_ls_dir\n# save and load bagdata\ndef save_bagdata(bagdata: Bag_data):\n    bagdata_path = os.path.join(bagdata.destination_folder, \"bagdata.pkl\")\n    pickle.dump(bagdata, open(bagdata_path, \"wb\"))\n    print(f\"save {type(bagdata)} in {bagdata_path}\")\n    return bagdata_path",
        "detail": "src.preprocess",
        "documentation": {}
    },
    {
        "label": "save_bagdata",
        "kind": 2,
        "importPath": "src.preprocess",
        "description": "src.preprocess",
        "peekOfCode": "def save_bagdata(bagdata: Bag_data):\n    bagdata_path = os.path.join(bagdata.destination_folder, \"bagdata.pkl\")\n    pickle.dump(bagdata, open(bagdata_path, \"wb\"))\n    print(f\"save {type(bagdata)} in {bagdata_path}\")\n    return bagdata_path\ndef load_bagdata(bagdata_path: os.path):\n    file = pathlib.Path(bagdata_path)\n    if file.exists() == False:\n        print(f\"there is no bagdata object\")\n    else:",
        "detail": "src.preprocess",
        "documentation": {}
    },
    {
        "label": "load_bagdata",
        "kind": 2,
        "importPath": "src.preprocess",
        "description": "src.preprocess",
        "peekOfCode": "def load_bagdata(bagdata_path: os.path):\n    file = pathlib.Path(bagdata_path)\n    if file.exists() == False:\n        print(f\"there is no bagdata object\")\n    else:\n        return pickle.load(open(bagdata_path, \"rb\"))",
        "detail": "src.preprocess",
        "documentation": {}
    },
    {
        "label": "source_1",
        "kind": 5,
        "importPath": "src.preprocess",
        "description": "src.preprocess",
        "peekOfCode": "source_1 = r'/Users/nguyenminhhieu/Documents/Job/HIWI_JOB/source_live_data'\ndestination_1 = r'/Users/nguyenminhhieu/Documents/Job/HIWI_JOB/live_data'\nstart_date_time_1 = datetime(2021, 6, 15, 0, 0, 0, 0)\nbagdata_1 = Bag_data(source_1, destination_1, start_date_time_1)\nbagdata_1.__repr__\nBag_data(2021-06-15 00:00:00) \nprocess all csv files created in source_folder after start_date_time:2021-06-15 00:00:00\n# saving and loading bag_data instance.\nsave(bagdata_1)\nbagdata_1 = load(destination_1)",
        "detail": "src.preprocess",
        "documentation": {}
    },
    {
        "label": "destination_1",
        "kind": 5,
        "importPath": "src.preprocess",
        "description": "src.preprocess",
        "peekOfCode": "destination_1 = r'/Users/nguyenminhhieu/Documents/Job/HIWI_JOB/live_data'\nstart_date_time_1 = datetime(2021, 6, 15, 0, 0, 0, 0)\nbagdata_1 = Bag_data(source_1, destination_1, start_date_time_1)\nbagdata_1.__repr__\nBag_data(2021-06-15 00:00:00) \nprocess all csv files created in source_folder after start_date_time:2021-06-15 00:00:00\n# saving and loading bag_data instance.\nsave(bagdata_1)\nbagdata_1 = load(destination_1)\n\"\"\"",
        "detail": "src.preprocess",
        "documentation": {}
    },
    {
        "label": "start_date_time_1",
        "kind": 5,
        "importPath": "src.preprocess",
        "description": "src.preprocess",
        "peekOfCode": "start_date_time_1 = datetime(2021, 6, 15, 0, 0, 0, 0)\nbagdata_1 = Bag_data(source_1, destination_1, start_date_time_1)\nbagdata_1.__repr__\nBag_data(2021-06-15 00:00:00) \nprocess all csv files created in source_folder after start_date_time:2021-06-15 00:00:00\n# saving and loading bag_data instance.\nsave(bagdata_1)\nbagdata_1 = load(destination_1)\n\"\"\"\nimport pickle",
        "detail": "src.preprocess",
        "documentation": {}
    },
    {
        "label": "bagdata_1",
        "kind": 5,
        "importPath": "src.preprocess",
        "description": "src.preprocess",
        "peekOfCode": "bagdata_1 = Bag_data(source_1, destination_1, start_date_time_1)\nbagdata_1.__repr__\nBag_data(2021-06-15 00:00:00) \nprocess all csv files created in source_folder after start_date_time:2021-06-15 00:00:00\n# saving and loading bag_data instance.\nsave(bagdata_1)\nbagdata_1 = load(destination_1)\n\"\"\"\nimport pickle\nimport os",
        "detail": "src.preprocess",
        "documentation": {}
    },
    {
        "label": "bagdata_1",
        "kind": 5,
        "importPath": "src.preprocess",
        "description": "src.preprocess",
        "peekOfCode": "bagdata_1 = load(destination_1)\n\"\"\"\nimport pickle\nimport os\nimport shutil\nfrom dateutil import parser\nfrom datetime import datetime\nimport pandas as pd\nimport numpy as np\nimport pathlib",
        "detail": "src.preprocess",
        "documentation": {}
    },
    {
        "label": "Bag_result",
        "kind": 6,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "peekOfCode": "class Bag_result:\n    def __init__(self, bagdata: preprocess.Bag_data, nameoption=\"\") -> None:\n        self.bagdata = bagdata\n        self.nameoption = nameoption\n        self.make_dir_Bag_result()\n        self.make_dir_data()\n        self.make_dir_plot()\n        self.datadict = import_bagdata_as_dict(bagdata)\n        self.interpolatefunct_dict = interpolation_datadict(self.datadict)\n        self.plotdata_df = make_datadf(self.datadict)",
        "detail": "src.store_results",
        "documentation": {}
    },
    {
        "label": "import_bagdata_as_dict",
        "kind": 2,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "peekOfCode": "def import_bagdata_as_dict(bagdata: preprocess.Bag_data, time_option=1) -> dict:\n    \"\"\"\n    load all csv files in target folder and make a dictionary,\n    whose values are the csv files and correspond keys\n    are transformed in s or min or h (our setting is h (3600))\n    ----------\n    bagdata: mk.Bagdata\n    time_option: int\n        1 for s,60 for min, 3600 for h\n    Returns",
        "detail": "src.store_results",
        "documentation": {}
    },
    {
        "label": "save_data_in_bagresult",
        "kind": 2,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "peekOfCode": "def save_data_in_bagresult(data, bagresult: Bag_result, nameoption=str):\n    if isinstance(data, dict):\n        dict_path = os.path.join(bagresult.data_dir, nameoption + \".npy\")\n        np.save(dict_path, data)\n        # print(f\"save {nameoption +'.npy'} in {dict_path}\")\n        # setattr(bagresult, nameoption, dict_path)\n        return dict_path\n    if isinstance(data, pd.DataFrame):\n        df_path = os.path.join(bagresult.data_dir, nameoption + \".csv\")\n        data.to_csv(df_path, index=False)",
        "detail": "src.store_results",
        "documentation": {}
    },
    {
        "label": "interpolation_datadict",
        "kind": 2,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "peekOfCode": "def interpolation_datadict(datadict: dict) -> dict:\n    f_dict = {}\n    for time, df in datadict.items():\n        tem_x = np.array([df[\"Frequency(ppm)\"]]).flatten()\n        tem_y = np.array([df[\"Intensity\"]]).flatten()\n        tem_f = interp1d(tem_x, tem_y, kind=\"cubic\")\n        f_dict.update({time: tem_f})\n    return f_dict\ndef make_datadf(datadict: dict) -> pd.DataFrame:\n    f_dict = interpolation_datadict(datadict)",
        "detail": "src.store_results",
        "documentation": {}
    },
    {
        "label": "make_datadf",
        "kind": 2,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "peekOfCode": "def make_datadf(datadict: dict) -> pd.DataFrame:\n    f_dict = interpolation_datadict(datadict)\n    time_col_index = list(f_dict.keys())\n    ppm_col = list(np.linspace(-26.3, 35.82, 65536))  # make it as parameters\n    cols_name = [\"Frequency\"] + time_col_index\n    data_df = pd.DataFrame(columns=cols_name)\n    data_df[\"Frequency\"] = ppm_col\n    for t in time_col_index:\n        data_df[t] = f_dict[t](data_df[\"Frequency\"].values)\n    return data_df",
        "detail": "src.store_results",
        "documentation": {}
    },
    {
        "label": "filter_datadf",
        "kind": 2,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "peekOfCode": "def filter_datadf(\n    df, timestr: float, timeend: float, ppmstr: float, ppmend: float\n) -> pd.DataFrame:\n    \"\"\"\n    function to filter the data df with desired ppm and time\n    \"\"\"\n    tem_df = df.loc[(df[\"Frequency\"] >= ppmstr) & (df[\"Frequency\"] <= ppmend)]\n    time_col_index = [col for col in list(tem_df.columns) if col != \"Frequency\"]\n    select_time_col = [\n        col for col in time_col_index if (col >= timestr) and (col <= timeend)",
        "detail": "src.store_results",
        "documentation": {}
    },
    {
        "label": "save_bagresult",
        "kind": 2,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "peekOfCode": "def save_bagresult(bagresult: Bag_result):\n    bagresult_path = os.path.join(bagresult.analysis_results, \"bagresult.pkl\")\n    pickle.dump(bagresult, open(bagresult_path, \"wb\"))\n    print(f\"save {type(bagresult)} in {bagresult_path}\")\n    return bagresult_path\ndef load_bagresult(bagresult_path):\n    file = pathlib.Path(bagresult_path)\n    if file.exists() == False:\n        print(f\"there is no bagresult object\")\n    else:",
        "detail": "src.store_results",
        "documentation": {}
    },
    {
        "label": "load_bagresult",
        "kind": 2,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "peekOfCode": "def load_bagresult(bagresult_path):\n    file = pathlib.Path(bagresult_path)\n    if file.exists() == False:\n        print(f\"there is no bagresult object\")\n    else:\n        return pickle.load(open(bagresult_path, \"rb\"))",
        "detail": "src.store_results",
        "documentation": {}
    },
    {
        "label": "source_1",
        "kind": 5,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "peekOfCode": "source_1 = r'/Users/nguyenminhhieu/Documents/Job/HIWI_JOB/source_live_data'\ndestination_1 = r'/Users/nguyenminhhieu/Documents/Job/HIWI_JOB/live_data'\nstart_date_time_1 = datetime(2021, 6, 15, 0, 0, 0, 0)\nbagdata_1 = preprocess.Bag_data(source_1, destination_1, start_date_time_1)\nbagdata_1.__repr__\n#Bag_data(2021-06-15 00:00:00) \n# We create a bag_result instance from this bag_data\nbagresult_1 = Bag_result(bagdata=bagdata_1, nameoption='_1')\n# saving and loading bag_result instance\nsave_bagresult(bagresult= bag_result_1)",
        "detail": "src.store_results",
        "documentation": {}
    },
    {
        "label": "destination_1",
        "kind": 5,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "peekOfCode": "destination_1 = r'/Users/nguyenminhhieu/Documents/Job/HIWI_JOB/live_data'\nstart_date_time_1 = datetime(2021, 6, 15, 0, 0, 0, 0)\nbagdata_1 = preprocess.Bag_data(source_1, destination_1, start_date_time_1)\nbagdata_1.__repr__\n#Bag_data(2021-06-15 00:00:00) \n# We create a bag_result instance from this bag_data\nbagresult_1 = Bag_result(bagdata=bagdata_1, nameoption='_1')\n# saving and loading bag_result instance\nsave_bagresult(bagresult= bag_result_1)\nload_bagresult(destination_folder= destination_1, bagresult_name='bagresult_1')",
        "detail": "src.store_results",
        "documentation": {}
    },
    {
        "label": "start_date_time_1",
        "kind": 5,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "peekOfCode": "start_date_time_1 = datetime(2021, 6, 15, 0, 0, 0, 0)\nbagdata_1 = preprocess.Bag_data(source_1, destination_1, start_date_time_1)\nbagdata_1.__repr__\n#Bag_data(2021-06-15 00:00:00) \n# We create a bag_result instance from this bag_data\nbagresult_1 = Bag_result(bagdata=bagdata_1, nameoption='_1')\n# saving and loading bag_result instance\nsave_bagresult(bagresult= bag_result_1)\nload_bagresult(destination_folder= destination_1, bagresult_name='bagresult_1')\n\"\"\"",
        "detail": "src.store_results",
        "documentation": {}
    },
    {
        "label": "bagdata_1",
        "kind": 5,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "peekOfCode": "bagdata_1 = preprocess.Bag_data(source_1, destination_1, start_date_time_1)\nbagdata_1.__repr__\n#Bag_data(2021-06-15 00:00:00) \n# We create a bag_result instance from this bag_data\nbagresult_1 = Bag_result(bagdata=bagdata_1, nameoption='_1')\n# saving and loading bag_result instance\nsave_bagresult(bagresult= bag_result_1)\nload_bagresult(destination_folder= destination_1, bagresult_name='bagresult_1')\n\"\"\"\n# %%",
        "detail": "src.store_results",
        "documentation": {}
    },
    {
        "label": "bagresult_1",
        "kind": 5,
        "importPath": "src.store_results",
        "description": "src.store_results",
        "peekOfCode": "bagresult_1 = Bag_result(bagdata=bagdata_1, nameoption='_1')\n# saving and loading bag_result instance\nsave_bagresult(bagresult= bag_result_1)\nload_bagresult(destination_folder= destination_1, bagresult_name='bagresult_1')\n\"\"\"\n# %%\nimport pickle\nimport os\nimport pandas as pd\nimport numpy as np",
        "detail": "src.store_results",
        "documentation": {}
    }
]